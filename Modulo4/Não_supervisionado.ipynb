{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Não-supervisionado.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Cc1NY1KYtAeK"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "import sklearn.metrics as sm\n",
        " \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        " \n",
        "# Only needed if you want to display your plots inline if using Notebook\n",
        "# change inline to auto if you have Spyder installed\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iris = datasets.load_iris()"
      ],
      "metadata": {
        "id": "wBIkiFQStGmV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mapeando rótulos de destino para nomes de destino"
      ],
      "metadata": {
        "id": "Zin6nb52tLr2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "species_dict = dict(zip(range(0, len(iris.target_names)), iris.target_names))\n",
        "\n",
        "iris_species = list((map(lambda x : species_dict[x], iris.target)))"
      ],
      "metadata": {
        "id": "Grt83FUKtMno"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cheque o nome das variáveis"
      ],
      "metadata": {
        "id": "Mz18rWB2tQHN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cheque o nome das espécies"
      ],
      "metadata": {
        "id": "-NjB-OmvtUEH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Coloque tudo em um dataset"
      ],
      "metadata": {
        "id": "6PsxmYkxtZIW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Você recebe uma matriz de pontos de tamanho 150x4. Como visto acima, nossas características são comprimento da sépala (cm), largura da sépala (cm), comprimento da pétala (cm), largura da pétala (cm).\n",
        "\n",
        "`matplotlib.pyplot` já foi importado como plt.\n",
        "\n",
        "Faça um gráfico de dispersão passando `x.Sepal_Length` e `x.Sepal_Width` para a função `plt.scatter()`. Faça um gráfico de dispersão passando `x.Petal_Length` e `x.Petal_Width` para a função `plt.scatter()`. Chame a função `plt.show()` para mostrar seu gráfico. Quantos clusters você vê?"
      ],
      "metadata": {
        "id": "dtTJHdTLtgP2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O tamanho dos dados na era moderna não é apenas um desafio para o hardware do computador, mas também um gargalo principal para o desempenho de muitos algoritmos de aprendizado de máquina. O principal objetivo de uma análise de PCA é identificar padrões nos dados; A PCA visa detectar a correlação entre as variáveis. Se existir uma forte correlação entre as variáveis, a tentativa de reduzir a dimensionalidade só faz sentido. Em poucas palavras, é disso que se trata o PCA: encontrar as direções de variação máxima em dados de alta dimensão e projetá-los em um subespaço dimensional menor enquanto retém a maioria das informações."
      ],
      "metadata": {
        "id": "b3RSytXdt1Rs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como o intervalo de valores dos dados brutos varia muito, em alguns algoritmos de aprendizado de máquina, as funções objetivas não funcionarão corretamente sem normalização. Por exemplo, a maioria dos classificadores calcula a distância entre dois pontos pela distância euclidiana. Se um dos recursos tiver uma ampla faixa de valores, a distância será regida por esse recurso específico. Portanto, o alcance de todas as feições deve ser normalizado para que cada feições contribua aproximadamente proporcionalmente à distância final.\n",
        "\n",
        "Dados não dimensionados também podem retardar ou até mesmo impedir a convergência de muitos estimadores baseados em gradiente. Existem vários métodos para normalizar dados. Para este tutorial, vamos usar o StandardScaler do scikit-learn."
      ],
      "metadata": {
        "id": "TrDVt1FNt7OK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "X_std = StandardScaler().fit_transform(x)"
      ],
      "metadata": {
        "id": "zMTACwlWtrQf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform the necessary imports\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Crie o scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Crie a estância de PCA\n",
        "pca = PCA()\n",
        "\n",
        "# Fit_transform \n",
        "X_norm = scaler.fit_transform(x)\n",
        "pca.fit(X_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QYJv4G9t99M",
        "outputId": "65bdf3f8-97f4-4c1b-f260-4561fedd70f4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PCA()"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plote a importância das variáveis"
      ],
      "metadata": {
        "id": "tPvZwPKKuMDw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Em um exercício anterior, você descobriu que a \"dimensão intrínseca\" era cerca de `k<4` do conjunto de dados da íris. Agora use o PCA para reduzir a dimensionalidade do conjunto de dados da íris, retendo apenas os 2 componentes mais importantes.\n",
        "\n",
        "Já fomos dimensionados acima, e está disponível como `X_norm`."
      ],
      "metadata": {
        "id": "ZrItGn9CyMes"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Crie uma instância do PCA chamada pca com `n_components=2`."
      ],
      "metadata": {
        "id": "WbkUm7THyUQ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use o método `.fit()` de pca para ajustá-lo aos dados de íris escalonados `X_norm`."
      ],
      "metadata": {
        "id": "efCUkJ-IyXfg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use o método `.transform()` do pca para transformar o `X_norm`. Atribua o resultado a pca_features."
      ],
      "metadata": {
        "id": "mkM_7uS8ycWR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plote o resultado"
      ],
      "metadata": {
        "id": "syvgSXJ2zB-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A partir do gráfico de dispersão do exercício anterior, você viu que os pontos parecem se separar em 3 grupos. Agora você criará um modelo do KMeans para encontrar 3 clusters e ajustá-lo aos pontos de dados do exercício anterior. Depois que o modelo for ajustado, você obterá os rótulos de cluster para alguns novos pontos usando o método `.predict()`.\n",
        "\n",
        "Você recebe os pontos do array do exercício anterior e também um array new_points."
      ],
      "metadata": {
        "id": "kG2hRFPuzJ34"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans"
      ],
      "metadata": {
        "id": "XbiUZgSjzDdE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Usando o `KMeans()`, crie uma instância do KMeans chamada model para encontrar 3 clusters. Para especificar o número de clusters, use o argumento de palavra-chave `n_clusters`."
      ],
      "metadata": {
        "id": "AabMM9RwQcG7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fite o modelo"
      ],
      "metadata": {
        "id": "Rd3jBk5VRBwo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use a função `pd.crosstab()` em `df['labels']` e `df['variedades']` para contar o número de vezes que cada espécie de íris coincide com cada rótulo de cluster. Atribuir o resultado a `ct`"
      ],
      "metadata": {
        "id": "4dAHHM45RQLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Hi9Cju4FRPPp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}